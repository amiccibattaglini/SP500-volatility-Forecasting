{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import (Metrics, \n",
    "                   real_vol, \n",
    "                   resample)\n",
    "\n",
    "from ML_library import (GarchRegressor,\n",
    "                        EWMARegressor,\n",
    "                        MaxGarchEWMARegressor)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from scipy.optimize import minimize\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 6]\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading the S&P 500 index\n",
    "ticker = '^GSPC'\n",
    "start_date = '1927-12-31'\n",
    "end_date = '2025-05-01'\n",
    "\n",
    "df_SP = yf.download(tickers = ticker, start = start_date, end = end_date)\n",
    "df_SP = df_SP.xs(\"^GSPC\", axis = 1, level = \"Ticker\")\n",
    "df_SP = df_SP[['Close']]\n",
    "df_SP['Return'] = np.log(df_SP['Close']/df_SP['Close'].shift(1))\n",
    "df_SP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### splitting training set and test set\n",
    "df_resampled = resample(df_SP, period = 'M')\n",
    "split_train = int(len(df_resampled)*0.6)\n",
    "split_test = int(len(df_resampled)*0.8)\n",
    "\n",
    "X, y = df_resampled.shift(1).dropna(), df_resampled['Real_vol'].iloc[1:]\n",
    "training_x, training_y = X.iloc[:split_train], y.iloc[:split_train]\n",
    "val_x, val_y = X.iloc[split_train:split_test], y.iloc[split_train:split_test]\n",
    "test_x, test_y = X.iloc[split_test:], y.iloc[split_test:]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(training_x.columns), figsize=(12, 5))\n",
    "\n",
    "for ax, col in zip(axes, training_x.columns):\n",
    "    sns.histplot(training_x[col], color=\"blue\", ax=ax)\n",
    "    ax.set_title(f\"Histogram of {col}\")\n",
    "    ax.legend([col]) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### feature engineering\n",
    "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#building the pipelines\n",
    "general_pipeline = make_pipeline(StandardScaler()) # for returns\n",
    "log_pipeline = make_pipeline(FunctionTransformer(func = np.log, inverse_func=np.exp, feature_names_out=\"one-to-one\"),\n",
    "                             StandardScaler()) # for realized volatility\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"log\", log_pipeline, [\"Real_vol\"])\n",
    "], \n",
    "remainder = general_pipeline)\n",
    "\n",
    "training_x_prepared = preprocessing.fit_transform(training_x)\n",
    "training_x_prepared.shape\n",
    "\n",
    "pd.DataFrame(training_x_prepared, columns = [\"Log-RealVol\", \"Return\"]).hist(bins = 50, \n",
    "                                                                            color = \"blue\", \n",
    "                                                                            density = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import randint\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the timeseries folds\n",
    "#tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "#garch\n",
    "initial_guess = [0.0001, 0.1, 0.8]\n",
    "garch_est = GarchRegressor(initial_guess[0], initial_guess[1], initial_guess[2]) # estimating the training error\n",
    "garch_est.fit(training_x) #training the model on all the training set \n",
    "predicted_vola_garch = garch_est.predict(training_x)\n",
    "\n",
    "#ewma\n",
    "ewma_est = EWMARegressor(lam = 0.9)\n",
    "ewma_est.fit(training_x)\n",
    "predicted_vola_ewma = ewma_est.predict(training_x)\n",
    "\n",
    "#max between garch and ewma\n",
    "max_est = MaxGarchEWMARegressor(garch_model = garch_est, ewma_model=ewma_est)\n",
    "max_est.fit(training_x)\n",
    "predicted_vola_max = max_est.predict(training_x)\n",
    "\n",
    "# Training performances and plot\n",
    "metrics_train = Metrics()\n",
    "metrics_train.performance_metrics(predicted_vola_garch, training_y, \"GARCH\")\n",
    "metrics_train.performance_metrics(predicted_vola_ewma, training_y, \"EWMA\")\n",
    "metrics_train.performance_metrics(predicted_vola_max, training_y, \"Max\")\n",
    "metrics_train.build_tabulate()\n",
    "\n",
    "plt.plot(training_y.index, predicted_vola_garch, label = 'Garch')\n",
    "plt.plot(training_y.index, predicted_vola_ewma, label = 'EWMA')\n",
    "plt.plot(training_y.index, predicted_vola_max, label = 'Max')\n",
    "plt.plot(training_y, label = 'Realized Volatility', alpha = 0.7)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the performance on the test set\n",
    "test_garch = garch_est.predict(test_x)\n",
    "test_ewma = ewma_est.predict(test_x)\n",
    "test_max = max_est.predict(test_x)\n",
    "\n",
    "metrics_test = Metrics()\n",
    "metrics_test.performance_metrics(test_garch, test_y, \"GARCH\")\n",
    "metrics_test.performance_metrics(test_ewma, test_y, \"EWMA\")\n",
    "metrics_test.performance_metrics(test_max, test_y, \"Max\")\n",
    "metrics_test.build_tabulate()\n",
    "\n",
    "plt.plot(test_y.index, test_garch, label = 'Garch')\n",
    "plt.plot(test_y.index, test_ewma, label = 'EWMA')\n",
    "plt.plot(test_y.index, test_max, label = 'Max')\n",
    "plt.plot(test_y, label = 'Realized Volatility', alpha = 0.7)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## linear models\n",
    "shrinkage_list = [1e-8, 1e-6, 1e-4, 0.01, 1, 10, 100, 1000]\n",
    "\n",
    "simple_rg = LinearRegression()\n",
    "lasso_rg = LassoCV(alphas = shrinkage_list, cv = 5)\n",
    "ridge_rg = RidgeCV(alphas = shrinkage_list, cv = 5)\n",
    "\n",
    "linear_models = [\n",
    "    ('lr', simple_rg),\n",
    "    ('lasso', lasso_rg),\n",
    "    ('ridge', ridge_rg)\n",
    "]\n",
    "rmse_cross = {}\n",
    "prediction_cross_val = {}\n",
    "trained_model = {}\n",
    "\n",
    "# Training the three linear models in the original variables\n",
    "for tuple in linear_models:\n",
    "    name = tuple[0]\n",
    "    model = tuple[1]\n",
    "    pipe = Pipeline([\n",
    "        ('preprocessing', preprocessing),\n",
    "        (name, model)\n",
    "    ])\n",
    "    #[name] = cross_val_score(pipe, training_x, training_y, cv = 5, scoring = 'neg_root_mean_squared_error')\n",
    "    #trainig the model on the whole trainig set\n",
    "    pipe.fit(training_x, training_y)\n",
    "    prediction_cross_val[name] = pipe.predict(training_x)\n",
    "    #storing the trained model\n",
    "    trained_model[name] = pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of the performance of the model in the trainig set\n",
    "#computing the Training Error for the three models\n",
    "metrics_train.performance_metrics(prediction_cross_val[\"lr\"], training_y, \"lr\")\n",
    "metrics_train.performance_metrics(prediction_cross_val[\"lasso\"], training_y, \"lasso\")\n",
    "metrics_train.performance_metrics(prediction_cross_val[\"ridge\"], training_y, \"ridge\")\n",
    "metrics_train.build_tabulate()\n",
    "\n",
    "#plotting the training results\n",
    "for name in prediction_cross_val.keys():\n",
    "    plt.plot(training_y.index, prediction_cross_val[name], label = f\"{name}\")\n",
    "plt.plot(training_y, label = 'Realized Volatility', alpha = 0.7)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eveluation of the model on the test set\n",
    "lr_model = trained_model[\"lr\"]\n",
    "lasso_model = trained_model[\"lasso\"]\n",
    "ridge_model = trained_model[\"ridge\"]\n",
    "\n",
    "lr_preds = lr_model.predict(test_x)\n",
    "lasso_preds = lasso_model.predict(test_x)\n",
    "ridge_preds = ridge_model.predict(test_x)\n",
    "\n",
    "metrics_test.performance_metrics(lr_preds, test_y, \"lr\")\n",
    "metrics_test.performance_metrics(lasso_preds, test_y, \"lasso\")\n",
    "metrics_test.performance_metrics(ridge_preds, test_y, \"ridge\")\n",
    "metrics_test.build_tabulate()\n",
    "\n",
    "plt.plot(test_y.index, lr_preds, label = 'lr')\n",
    "plt.plot(test_y.index, lasso_preds, label = 'lasso')\n",
    "plt.plot(test_y.index, ridge_preds, label = 'ridge')\n",
    "plt.plot(test_y, label = 'Realized Volatility', alpha = 0.7)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeSeriesSplit (for time series data)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "rnd_forest = RandomForestRegressor(random_state=42)\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('random_forest', rnd_forest)\n",
    "])\n",
    "\n",
    "# RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'random_forest__n_estimators': randint(low=100, high=1000),\n",
    "    'random_forest__max_depth': randint(low=5, high=50),\n",
    "    'random_forest__min_samples_leaf': randint(low=2, high=20),\n",
    "    'random_forest__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'random_forest__min_samples_split': randint(low=2, high=20)\n",
    "}\n",
    "\n",
    "grid_search_forest = RandomizedSearchCV(\n",
    "    full_pipeline,  \n",
    "    param_grid,  \n",
    "    cv=tscv,  \n",
    "    n_iter=10,  \n",
    "    random_state=42,\n",
    "    scoring='neg_root_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search_forest.fit(training_x, training_y)\n",
    "\n",
    "# Display the results\n",
    "cv_res = pd.DataFrame(grid_search_forest.cv_results_).sort_values(by='mean_test_score', ascending=False)\n",
    "cv_res.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the performance of the Random forest on the training set\n",
    "rnd_forest_best = grid_search_forest.best_estimator_\n",
    "rnd_forest_best.fit(training_x, training_y)\n",
    "rnd_forest_training = rnd_forest_best.predict(training_x)\n",
    "\n",
    "metrics_train.performance_metrics(rnd_forest_training, training_y, \"rnd forest\")\n",
    "metrics_train.build_tabulate()\n",
    "\n",
    "#plotting the training results\n",
    "\n",
    "plt.plot(training_y.index, rnd_forest_training, label = \"rnd forest\")\n",
    "plt.plot(training_y, label = 'Realized Volatility', alpha = 0.7)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the performance of the random forest on the test set\n",
    "\n",
    "rnd_forest_test = rnd_forest_best.predict(test_x)\n",
    "\n",
    "metrics_test.performance_metrics(rnd_forest_test, test_y, \"rnd forest\")\n",
    "metrics_test.build_tabulate()\n",
    "\n",
    "plt.plot(test_y.index, rnd_forest_test, label = 'rnd forest')\n",
    "plt.plot(test_y, label = 'Realized Volatility', alpha = 0.7)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
